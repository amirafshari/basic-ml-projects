{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5281bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "    \n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a374641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(pr,re,f1):\n",
    "    print (f'Precision: {pr}' , '\\n' + f'Recall: {re}', '\\n' + f'f1: {f1}')\n",
    "\n",
    "\n",
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.grid(True)\n",
    "    \n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate (Recall)', fontsize=16)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    \n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.figure(figsize=(8, 4))                                              \n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.legend(loc=\"center right\", fontsize=16)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.grid(True)\n",
    "    plt.axis([-50000, 50000, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist = load_digits()\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a03764",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"].astype(np.uint8)\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ada20c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5de637",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "* svc (C-Support Vector Classifier)  \n",
    "* OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef2ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fda4a9d8",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a545cd",
   "metadata": {},
   "source": [
    "### Metrics  \n",
    "    1.Precision  \n",
    "    2.Recall  \n",
    "    3.f1_score (Harmonic Mean of Precision and Recall)  \n",
    "### Curves  \n",
    "    4.Precision vs Recall  \n",
    "    5.Precision-Recall vs Threshold  \n",
    "    6.ROC  \n",
    "    7.ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fafb5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score,\\\n",
    "                            f1_score, precision_recall_curve, roc_curve, \\\n",
    "                            roc_auc_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
